{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:06.396849Z",
     "start_time": "2021-02-08T17:50:06.381813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> \n",
       "@import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');\n",
       "a {color: #37c9e1; font-family: 'Roboto';} \n",
       "h1 {color: #C20E69; font-family: 'Poppins'} \n",
       "h2, h3 {color: #25B89B; font-family: 'Poppins';}\n",
       "h4 {color: #818286; font-family: 'Roboto';}\n",
       "                                      \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> \n",
    "@import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');\n",
    "a {color: #37c9e1; font-family: 'Roboto';} \n",
    "h1 {color: #C20E69; font-family: 'Poppins'} \n",
    "h2, h3 {color: #25B89B; font-family: 'Poppins';}\n",
    "h4 {color: #818286; font-family: 'Roboto';}\n",
    "                                      \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PROJECT OBJECTIVE**: \n",
    "We will build a recommendation system using popularity based and collaborative filtering methods to recommend\n",
    "mobile phones to a user which are most popular and personalised respectively.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CONTEXT:** \n",
    "India is the second largest market globally for smartphones after China. About 134 million smartphones were sold across India\n",
    "in the year 2017 and is estimated to increase to about 442 million in 2022. India ranked second in the average time spent on mobile web by\n",
    "smartphone users across Asia Pacific. The combination of very high sales volumes and the average smartphone consumer behaviour has\n",
    "made India a very attractive market for foreign vendors. As per Consumer behaviour, 97% of consumers turn to a search engine when they\n",
    "are buying a product vs. 15% who turn to social media. If a seller succeeds to publish smartphones based on user’s behaviour/choice at the\n",
    "right place, there are 90% chances that user will enquire for the same.\n",
    "\n",
    "`This Case Study is targeted to build a recommendation system based on individual consumer’s behaviour or choice.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA DESCRIPTION:**\n",
    "- author : name of the person who gave the rating\n",
    "- country : country the person who gave the rating belongs to\n",
    "- data : date of the rating\n",
    "- domain: website from which the rating was taken from\n",
    "- extract: rating content\n",
    "- language: language in which the rating was given\n",
    "- product: name of the product/mobile phone for which the rating was given\n",
    "- score: average rating for the phone\n",
    "- score_max: highest rating given for the phone\n",
    "- source: source from where the rating was taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='importing'>Importing the necessary libraries📗</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Packages used**\n",
    "- Numpy: 1.19.3\n",
    "- Pandas: 1.1.4\n",
    "- matplotlib: 3.2.1\n",
    "- Seaborn: 0.10.1\n",
    "- MissingNo: 0.4.2\n",
    "- Sklearn: 0.22.2.post1\n",
    "- Pandas_profiling: 2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:15.681330Z",
     "start_time": "2021-02-08T17:50:13.829660Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from zipfile import ZipFile\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "# import sklearn.external.joblib as extjoblib\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#import the reqired libraries\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "\n",
    "from scipy.spatial.distance import correlation, cosine\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import sys, os\n",
    "from contextlib import contextmanager\n",
    "%matplotlib inline\n",
    "\n",
    "# filterwarnings to ignore all unnecessary warnings and logs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#declaring metric as global which can be changed by the user later\n",
    "global metric\n",
    "metric='cosine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='reading'>Reading the dataset 📚</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:31.152366Z",
     "start_time": "2021-02-08T17:50:16.277339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the dataset and give the column names\n",
    "# columns=['phone_url','date','lang','country','source','domain','score','score_max','extract','author','product']\n",
    "phone_user_review1_df=pd.read_csv('phone_user_review_file_1.csv',encoding = \"ISO-8859-1\")\n",
    "phone_user_review2_df=pd.read_csv('phone_user_review_file_2.csv',encoding = \"ISO-8859-1\")\n",
    "phone_user_review3_df=pd.read_csv('phone_user_review_file_3.csv',encoding = \"ISO-8859-1\")\n",
    "phone_user_review4_df=pd.read_csv('phone_user_review_file_4.csv',encoding = \"ISO-8859-1\")\n",
    "phone_user_review5_df=pd.read_csv('phone_user_review_file_5.csv',encoding = \"ISO-8859-1\")\n",
    "phone_user_review6_df=pd.read_csv('phone_user_review_file_6.csv',encoding = \"ISO-8859-1\")\n",
    "# Concatenating dataframes without duplicates \n",
    "combined_phone_user_review_df = pd.concat([phone_user_review1_df\n",
    "                                           ,phone_user_review2_df, phone_user_review3_df, \n",
    "                                           phone_user_review4_df, phone_user_review5_df,phone_user_review6_df\n",
    "                                          ]).drop_duplicates() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:31.419371Z",
     "start_time": "2021-02-08T17:50:31.390331Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_phone_user_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:31.697332Z",
     "start_time": "2021-02-08T17:50:31.685333Z"
    }
   },
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "rows, columns = combined_phone_user_review_df.shape\n",
    "print(Fore.YELLOW + \"No of rows: \", Style.RESET_ALL,rows) \n",
    "print(Fore.YELLOW + \"No of columns: \", Style.RESET_ALL,columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:32.228335Z",
     "start_time": "2021-02-08T17:50:31.984334Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df = combined_phone_user_review_df.sample(n = 100000, random_state = 612) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:32.648332Z",
     "start_time": "2021-02-08T17:50:32.594333Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:32.679332Z",
     "start_time": "2021-02-08T17:50:32.651334Z"
    }
   },
   "outputs": [],
   "source": [
    "rows, columns = sample_df.shape\n",
    "print(Fore.YELLOW + \"No of rows: \", Style.RESET_ALL,rows) \n",
    "print(Fore.YELLOW + \"No of columns: \", Style.RESET_ALL,columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:33.609331Z",
     "start_time": "2021-02-08T17:50:33.346334Z"
    }
   },
   "outputs": [],
   "source": [
    "# It is very important to check and remove data duplicates. \n",
    "# Else our model may break or report overly optimistic / pessimistic performance results\n",
    "dupes=sample_df.duplicated()\n",
    "print(' The number of duplicates in the dataset are:',sum(dupes), '\\n')\n",
    "dupes_record=pd.DataFrame(sample_df[dupes])\n",
    "print(' The duplicate observations are:') \n",
    "dupes_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:34.268332Z",
     "start_time": "2021-02-08T17:50:33.924337Z"
    }
   },
   "outputs": [],
   "source": [
    "# After dropping duplicates\n",
    "sample_df.drop_duplicates(keep=\"first\")\n",
    "rows, columns = sample_df.shape\n",
    "print(Fore.YELLOW + \"No of rows: \", Style.RESET_ALL,rows) \n",
    "print(Fore.YELLOW + \"No of columns: \", Style.RESET_ALL,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='basic'>Basic Data Exploration 🏕️</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check for Data type of columns\n",
    "2. Check for null values.\n",
    "3. Check for outliers\n",
    "4. Look for the category distribution in categorical columns\n",
    "5. Plot for correlation\n",
    "6. Look for new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:34.664332Z",
     "start_time": "2021-02-08T17:50:34.651334Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check Data types\n",
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:42.604368Z",
     "start_time": "2021-02-08T17:50:34.667336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datetime conversion using astype for date column:\n",
    "sample_df['date'] = sample_df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:43.244891Z",
     "start_time": "2021-02-08T17:50:43.231893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datetime conversion using astype for date column:\n",
    "# sample_df['score'] = pd.to_numeric(sample_df['score'])\n",
    "sample_df['score'] = sample_df['score'].round().astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:43.589415Z",
     "start_time": "2021-02-08T17:50:43.576416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datetime conversion using astype for date column:\n",
    "# sample_df['score_max'] = pd.to_numeric(sample_df['score_max'])\n",
    "sample_df['score_max'] = sample_df['score_max'].round().astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:43.885462Z",
     "start_time": "2021-02-08T17:50:43.873412Z"
    }
   },
   "outputs": [],
   "source": [
    "#Again check Data types\n",
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#9703; Categorical & Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:44.197414Z",
     "start_time": "2021-02-08T17:50:44.168413Z"
    }
   },
   "outputs": [],
   "source": [
    "def cols():\n",
    "    cat_cols = [col for col in sample_df.columns if sample_df[col].dtypes == \"O\"]\n",
    "    if len(cat_cols) == 0:\n",
    "        print(\"There is no Categorical Column\")\n",
    "    else:\n",
    "        print(\"Number of Categorical Column: \", len(cat_cols),\"\\n\",cat_cols)\n",
    "    \n",
    "    num_cols = [col for col in sample_df.columns if sample_df[col].dtypes != \"O\"]\n",
    "    if len(num_cols) == 0:\n",
    "        print(\"There is no Numerical Column\")\n",
    "    print(\"Number of Numerical Columns: \", len(num_cols),\"\\n\",num_cols)\n",
    "cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:44.229411Z",
     "start_time": "2021-02-08T17:50:44.200415Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping less relevent columns\n",
    "''' dropping multiple column based on name'''\n",
    "sample_df.drop(['phone_url', 'extract', 'domain', 'date','lang', 'country', 'source'], axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:44.291413Z",
     "start_time": "2021-02-08T17:50:44.231412Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:45.240413Z",
     "start_time": "2021-02-08T17:50:45.133417Z"
    }
   },
   "outputs": [],
   "source": [
    "#display in each column how many null values are there\n",
    "sample_df.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:45.256413Z",
     "start_time": "2021-02-08T17:50:45.243416Z"
    }
   },
   "outputs": [],
   "source": [
    "# determine the threshold for missing values\n",
    "def assess_NA(data):\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe denoting the total number of NA values and the percentage of NA values in each column.\n",
    "    The column names are noted on the index.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dataframe\n",
    "    \"\"\"\n",
    "    # pandas series denoting features and the sum of their null values\n",
    "    null_sum = data.isnull().sum()# instantiate columns for missing data\n",
    "    total = null_sum.sort_values(ascending=False)\n",
    "    percent = ( ((null_sum / len(data.index))*100).round(2) ).sort_values(ascending=False)\n",
    "    \n",
    "    # concatenate along the columns to create the complete dataframe\n",
    "    df_NA = pd.concat([total, percent], axis=1, keys=['Number of NA', 'Percent NA'])\n",
    "    \n",
    "    # drop rows that don't have any missing data; omit if you want to keep all rows\n",
    "    df_NA = df_NA[ (df_NA.T != 0).any() ]\n",
    "    \n",
    "    return df_NA     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:45.318414Z",
     "start_time": "2021-02-08T17:50:45.258415Z"
    }
   },
   "outputs": [],
   "source": [
    "df_NA = assess_NA(sample_df)\n",
    "df_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.481927Z",
     "start_time": "2021-02-08T17:50:46.074414Z"
    }
   },
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(figsize = (14,10))\n",
    "sns.heatmap(sample_df.isnull() , cbar = False, cmap = \"YlGnBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.590928Z",
     "start_time": "2021-02-08T17:50:48.484929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code to get number of categories in missing value columns\n",
    "print(\"Number of Categories in: \")\n",
    "for ColName in sample_df[['author','product']]:\n",
    "    print(\"{} = {}\".format(ColName,       len(sample_df[ColName].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute / Replace Missing Values with Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.605928Z",
     "start_time": "2021-02-08T17:50:48.593928Z"
    }
   },
   "outputs": [],
   "source": [
    "# imputing missing data with median value can only be done with numerical data.\n",
    "sample_df['score'].fillna(sample_df['score'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.621928Z",
     "start_time": "2021-02-08T17:50:48.607929Z"
    }
   },
   "outputs": [],
   "source": [
    "# imputing missing data with median value can only be done with numerical data.\n",
    "sample_df['score_max'].fillna(sample_df['score_max'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.701932Z",
     "start_time": "2021-02-08T17:50:48.624929Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df['author'].fillna(sample_df['author'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.749931Z",
     "start_time": "2021-02-08T17:50:48.704929Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df['product'].fillna(sample_df['product'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.795929Z",
     "start_time": "2021-02-08T17:50:48.752932Z"
    }
   },
   "outputs": [],
   "source": [
    "df_NA = assess_NA(sample_df)\n",
    "df_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.856929Z",
     "start_time": "2021-02-08T17:50:48.798929Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As rule of thumb, skewness can be interpreted like this:**\n",
    "\n",
    "`Skewness`\n",
    "- Fairly Symmetrical\t-0.5 to 0.5\n",
    "- Moderate Skewed\t-0.5 to -1.0 and 0.5 to 1.0\n",
    "- Highly Skewed\t< -1.0 and > 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.902929Z",
     "start_time": "2021-02-08T17:50:48.859930Z"
    }
   },
   "outputs": [],
   "source": [
    "# skewness along the index axis \n",
    "sample_df.skew(axis = 0, skipna = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:48.948931Z",
     "start_time": "2021-02-08T17:50:48.905932Z"
    }
   },
   "outputs": [],
   "source": [
    "# skewness along the index axis \n",
    "sample_df.kurt(axis = 0, skipna = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:49.994926Z",
     "start_time": "2021-02-08T17:50:48.950931Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(15,8))\n",
    "sns.distplot(sample_df['score'],ax=ax[0],kde=True,hist=False)\n",
    "sns.distplot(sample_df['score_max'],ax=ax[0],kde=True,hist=False)\n",
    "plt.show()\n",
    "print(sample_df.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:50.026926Z",
     "start_time": "2021-02-08T17:50:49.997928Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sample_df['score'].astype(float).skew())\n",
    "print(sample_df['score'].astype(float).kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:50.056927Z",
     "start_time": "2021-02-08T17:50:50.029927Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sample_df['score_max'].astype(float).skew())\n",
    "print(sample_df['score_max'].astype(float).kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:50.229930Z",
     "start_time": "2021-02-08T17:50:50.059931Z"
    }
   },
   "outputs": [],
   "source": [
    "#display 5 point summary of dataframe\n",
    "sample_df.describe([0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:50.245929Z",
     "start_time": "2021-02-08T17:50:50.231929Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:50.967976Z",
     "start_time": "2021-02-08T17:50:50.890929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summary statistics of 'rating' variable\n",
    "sample_df['score'].describe([0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:50.983930Z",
     "start_time": "2021-02-08T17:50:50.970931Z"
    }
   },
   "outputs": [],
   "source": [
    "# find minimum and maximum ratings\n",
    "print('The minimum score is: %d' %(sample_df['score'].min()))\n",
    "print('The maximum score is: %d' %(sample_df['score'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Score are on scale of 0-10<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:54.798986Z",
     "start_time": "2021-02-08T17:50:54.346931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the distribution of ratings \n",
    "with sns.axes_style('white'):\n",
    "    g = sns.factorplot(\"score\", data=sample_df, aspect=2.0,kind='count')\n",
    "    g.set_ylabels(\"Total number of score\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:55.702927Z",
     "start_time": "2021-02-08T17:50:54.799927Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "data = sample_df['score'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / sample_df.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "# Create layout\n",
    "layout = dict(title = 'Distribution Of {} Phone-ratings'.format(sample_df.shape[0]),\n",
    "              xaxis = dict(title = 'Rating'),\n",
    "              yaxis = dict(title = 'Count'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that more that 80% of all scorings in the data are 6,7,8, 9 and 10, and very few ratings around 15%-18% are in the lower ratings range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Distribution By Product (Phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:55.904963Z",
     "start_time": "2021-02-08T17:50:55.704930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of ratings per phone\n",
    "data = sample_df.groupby('product')['score'].count().clip(upper=50)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Histogram(x = data.values,\n",
    "                     name = 'Scores',\n",
    "                     xbins = dict(start = 0,\n",
    "                                  end = 50,\n",
    "                                  size = 2))\n",
    "# Create layout\n",
    "layout = go.Layout(title = 'Distribution Of Number of Scores Per Phone (Clipped at 50)',\n",
    "                   xaxis = dict(title = 'Number of Scores Per Phone'),\n",
    "                   yaxis = dict(title = 'Count'),\n",
    "                   bargap = 0.2)\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:55.998986Z",
     "start_time": "2021-02-08T17:50:55.906958Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df.groupby('product')['score'].count().reset_index().sort_values('score', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Distribution By Authors (Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:56.404926Z",
     "start_time": "2021-02-08T17:50:56.001929Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of ratings per book\n",
    "data = sample_df.groupby('author')['score'].count().clip(upper=50)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Histogram(x = data.values,\n",
    "                     name = 'Scores',\n",
    "                     xbins = dict(start = 0,\n",
    "                                  end = 50,\n",
    "                                  size = 2))\n",
    "# Create layout\n",
    "layout = go.Layout(title = 'Distribution Of Number of Scores Per User (Clipped at 50)',\n",
    "                   xaxis = dict(title = 'Number of Scores Per User'),\n",
    "                   yaxis = dict(title = 'Count'),\n",
    "                   bargap = 0.2)\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:56.653931Z",
     "start_time": "2021-02-08T17:50:56.406928Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df.groupby('author')['score'].count().reset_index().sort_values('score', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the users gave more than 5 ratings, and very few users gave many ratings, although the most productive user have given 9827 ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T18:06:21.233743Z",
     "start_time": "2021-02-01T18:06:21.225228Z"
    }
   },
   "source": [
    "To reduce the dimensionality of the dataset, we will filter out rarely rated product and rarely rating authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:59.078998Z",
     "start_time": "2021-02-08T17:50:58.932961Z"
    }
   },
   "outputs": [],
   "source": [
    "min_phone_ratings = 50\n",
    "filter_products = sample_df['product'].value_counts() > min_phone_ratings\n",
    "filter_products = filter_products[filter_products].index.tolist()\n",
    "\n",
    "min_user_ratings = 50\n",
    "filter_users = sample_df['author'].value_counts() > min_user_ratings\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "df_new = sample_df[(sample_df['product'].isin(filter_products)) & (sample_df['author'].isin(filter_users))]\n",
    "print('The original data frame shape:\\t{}'.format(sample_df.shape))\n",
    "print('The new data frame shape:\\t{}'.format(df_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:59.376961Z",
     "start_time": "2021-02-08T17:50:59.362927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a series object containing the count of unique elements\n",
    "# in each column of dataframe\n",
    "uniqueValues = df_new.nunique()\n",
    "print('Count of unique values in each column :')\n",
    "print(uniqueValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:50:59.731929Z",
     "start_time": "2021-02-08T17:50:59.703930Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Fore.YELLOW + \"The total phones are\",Style.RESET_ALL,f\"{df_new['product'].count()},\", Fore.BLUE + \"from those the unique types are\", Style.RESET_ALL, f\"{df_new['product'].value_counts().shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:00.094931Z",
     "start_time": "2021-02-08T17:51:00.065930Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Fore.YELLOW + \"The total users are\",Style.RESET_ALL,f\"{df_new['author'].count()},\", Fore.BLUE + \"from those the unique types are\", Style.RESET_ALL, f\"{df_new['author'].value_counts().shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider only ratings from 1-10 and leave 0s in column `Score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:00.420930Z",
     "start_time": "2021-02-08T17:51:00.407928Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new['score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:00.436932Z",
     "start_time": "2021-02-08T17:51:00.423928Z"
    }
   },
   "outputs": [],
   "source": [
    "#Hence segragating implicit and explict ratings datasets\n",
    "ratings_explicit = df_new[df_new.score != 0]\n",
    "ratings_implicit = df_new[df_new.score == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:01.089929Z",
     "start_time": "2021-02-08T17:51:01.076928Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_new.shape)\n",
    "print(ratings_explicit.shape)\n",
    "print(ratings_implicit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:01.105927Z",
     "start_time": "2021-02-08T17:51:01.090929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Top 10 users based on rating\n",
    "most_rated = ratings_explicit.groupby('author').size().sort_values(ascending=False)[:10]\n",
    "most_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:01.730963Z",
     "start_time": "2021-02-08T17:51:01.716967Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(sample_df)\n",
    "counts = ratings_explicit['author'].value_counts()\n",
    "df_final = ratings_explicit[ratings_explicit['author'].isin(counts[counts >= 50].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:02.038927Z",
     "start_time": "2021-02-08T17:51:02.025927Z"
    }
   },
   "outputs": [],
   "source": [
    "counts1 = pd.value_counts(df_final['author'])\n",
    "counts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:02.395967Z",
     "start_time": "2021-02-08T17:51:02.366929Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['author'].isin(counts1[counts1 >= 50].index)]\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:02.720933Z",
     "start_time": "2021-02-08T17:51:02.706928Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:03.046963Z",
     "start_time": "2021-02-08T17:51:03.031930Z"
    }
   },
   "outputs": [],
   "source": [
    "# ratings_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:03.388971Z",
     "start_time": "2021-02-08T17:51:03.373927Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset,Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "\n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:03.727933Z",
     "start_time": "2021-02-08T17:51:03.714927Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:04.069931Z",
     "start_time": "2021-02-08T17:51:04.056927Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:04.523930Z",
     "start_time": "2021-02-08T17:51:04.494929Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(df_final[['author', 'product', 'score']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:05.022929Z",
     "start_time": "2021-02-08T17:51:05.008928Z"
    }
   },
   "outputs": [],
   "source": [
    "data.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:05.541929Z",
     "start_time": "2021-02-08T17:51:05.512934Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset,Reader\n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(df_final[['author', 'product', 'score']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:05.556931Z",
     "start_time": "2021-02-08T17:51:05.544927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data to train and test\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:06.396927Z",
     "start_time": "2021-02-08T17:51:06.382927Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset.all_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:06.417928Z",
     "start_time": "2021-02-08T17:51:06.399928Z"
    }
   },
   "outputs": [],
   "source": [
    "# However the ids are the inner ids and not the raw ids\n",
    "# raw ids can be obatined as follows\n",
    "\n",
    "print(trainset.to_raw_uid(0))\n",
    "#print(trainset.to_raw_iid(1066))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:07.176957Z",
     "start_time": "2021-02-08T17:51:07.162926Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, KNNWithMeans\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:07.237927Z",
     "start_time": "2021-02-08T17:51:07.178930Z"
    }
   },
   "outputs": [],
   "source": [
    "svd_model = SVD(n_factors=5,biased=False)\n",
    "svd_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:07.968929Z",
     "start_time": "2021-02-08T17:51:07.954930Z"
    }
   },
   "outputs": [],
   "source": [
    "testset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:07.984932Z",
     "start_time": "2021-02-08T17:51:07.970930Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = svd_model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:08.855932Z",
     "start_time": "2021-02-08T17:51:08.842932Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute RMSE\n",
    "accuracy.rmse(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:51:10.962981Z",
     "start_time": "2021-02-08T17:51:09.295929Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Surprise library, we will benchmark the following algorithms\n",
    "\n",
    "### Basic algorithms\n",
    "\n",
    "#### NormalPredictor\n",
    "\n",
    "* NormalPredictor algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal. This is one of the most basic algorithms that do not do much work.\n",
    "\n",
    "#### BaselineOnly\n",
    "\n",
    "* BasiclineOnly algorithm predicts the baseline estimate for given user and item.\n",
    "\n",
    "### k-NN algorithms\n",
    "\n",
    "#### KNNBasic\n",
    "\n",
    "* KNNBasic is a basic collaborative filtering algorithm.\n",
    "\n",
    "#### KNNWithMeans\n",
    "\n",
    "* KNNWithMeans is basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "\n",
    "#### KNNWithZScore\n",
    "\n",
    "* KNNWithZScore is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
    "\n",
    "#### KNNBaseline\n",
    "\n",
    "* KNNBaseline is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "\n",
    "### Matrix Factorization-based algorithms\n",
    "\n",
    "#### SVD\n",
    "\n",
    "* SVD algorithm is equivalent to Probabilistic Matrix Factorization (http://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf)\n",
    "\n",
    "#### SVDpp\n",
    "\n",
    "* The SVDpp algorithm is an extension of SVD that takes into account implicit ratings.\n",
    "\n",
    "#### NMF\n",
    "\n",
    "* NMF is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD.\n",
    "\n",
    "### Slope One\n",
    "\n",
    "* Slope One is a straightforward implementation of the SlopeOne algorithm. (https://arxiv.org/abs/cs/0702144)\n",
    "\n",
    "### Co-clustering\n",
    "\n",
    "* Co-clustering is a collaborative filtering algorithm based on co-clustering (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.6458&rep=rep1&type=pdf)\n",
    "\n",
    "\n",
    "We use rmse as our accuracy metric for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:19.258951Z",
     "start_time": "2021-02-08T17:51:11.305933Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE','MAE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:19.274932Z",
     "start_time": "2021-02-08T17:53:19.264932Z"
    }
   },
   "outputs": [],
   "source": [
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:20.196930Z",
     "start_time": "2021-02-08T17:53:20.158936Z"
    }
   },
   "outputs": [],
   "source": [
    "surprise_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaselineOnly algorithm gave us the best rmse, therefore, we will proceed further with BaselineOnly and use Alternating Least Squares (ALS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:20.648930Z",
     "start_time": "2021-02-08T17:53:20.587934Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Using ALS')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the train_test_split() to sample a trainset and a testset with given sizes, and use the accuracy metric of rmse. We’ll then use the fit() method which will train the algorithm on the trainset, and the test() method which will return the predictions made from the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:36.627994Z",
     "start_time": "2021-02-08T17:53:36.597930Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:36.642986Z",
     "start_time": "2021-02-08T17:53:36.629930Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = algo.trainset\n",
    "print(algo.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:36.658933Z",
     "start_time": "2021-02-08T17:53:36.644931Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = df.uid.apply(get_Iu)\n",
    "df['Ui'] = df.iid.apply(get_Ui)\n",
    "df['err'] = abs(df.est - df.rui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:36.673934Z",
     "start_time": "2021-02-08T17:53:36.661934Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:37.930932Z",
     "start_time": "2021-02-08T17:53:37.916935Z"
    }
   },
   "outputs": [],
   "source": [
    "best_predictions = df.sort_values(by='err')[:10]\n",
    "worst_predictions = df.sort_values(by='err')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:37.961931Z",
     "start_time": "2021-02-08T17:53:37.931931Z"
    }
   },
   "outputs": [],
   "source": [
    "best_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are the best predictions, and they are not lucky guesses. Because Ui is anywhere between 25 to 148, they are not really small, meaning that significant number of users have rated the target product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:53:38.814934Z",
     "start_time": "2021-02-08T17:53:38.785933Z"
    }
   },
   "outputs": [],
   "source": [
    "worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst predictions look pretty surprise. Let's look in more details of the First Product \"OnePlus X (Onyx, 16GB)\", the product was rated by 28 users, user \"Amazon Customer\" rated 2, our BaselineOnly algorithm predicts 8.30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:56:02.603497Z",
     "start_time": "2021-02-08T17:56:02.579497Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new.loc[df_new['product'] == 'OnePlus X (Onyx, 16GB)']['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:56:05.165349Z",
     "start_time": "2021-02-08T17:56:05.108312Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "df_new.loc[df_new['product'] == 'OnePlus 3 (Soft Gold, 64 GB)']['score'].hist()\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('Number of scores')\n",
    "plt.title('Number of scores OnePlus 3T has received')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out, most of the ratings this product received was between [6-10], in another word, most of the users in the data rated this phone [6-10], only very few users rated 2. Same with the other predictions in \"worst predictions\" list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Phone relevance and recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:13:50.974493Z",
     "start_time": "2021-02-08T17:13:50.946484Z"
    }
   },
   "source": [
    "**Precision@k = Recommended items that are relevant/Recommended items**\n",
    "\n",
    "**Recall@k= Recommended items that are relevant/Relevant items**\n",
    "\n",
    "_Precision at k is the proportion of recommended items in the top-k set that are relevant_\n",
    "\n",
    "Its interpretation is as follows. Suppose that my precision at 10 in a top-10 recommendation problem is 80%. This means that 80% of the recommendation I make are relevant to the user.\n",
    "\n",
    "\n",
    "_Recall at k is the proportion of relevant items found in the top-k recommendations_\n",
    "\n",
    "Suppose that we computed recall at 10 and found it is 40% in our top-10 recommendation system. This means that 40% of the total number of the relevant items appear in the top-k results.\n",
    "\n",
    "An item is considered relevant if its true rating rui is greater than a given threshold. An item is considered recommended if its estimated rating r^ui is greater than the threshold, and if it is among the k highest estimated ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:56:20.918407Z",
     "start_time": "2021-02-08T17:56:20.581461Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "\n",
    "def precision_recall_at_k(predictions, k=20, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended phone that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant phone that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=20)\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=20, threshold=4)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:56:21.590678Z",
     "start_time": "2021-02-08T17:56:21.544617Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=20):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "# First train an BaselineOnly algorithm on the smartphone dataset.\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = get_top_n(predictions, n=20)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "for uid, user_ratings in top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise the insights.\n",
    "\n",
    "Model-based Collaborative Filtering is a personalised recommender system, the recommendations are based on the past behavior of the user and it is not dependent on any additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
